# .github/workflows/complete_football_odds_collection.yml
name: Complete Football Odds Collection (TOUS les marchÃ©s et bookmakers)

# DÃ©clenchement manuel uniquement
on:
  workflow_dispatch:
    inputs:
      league_filter:
        description: 'Filtrer par ligue (optionnel, ex: ENG1,FRA1) - laissez vide pour toutes'
        required: false
        default: ''
        type: string
      batch_size:
        description: 'Taille des batches (dÃ©faut: 25)'
        required: false
        default: '25'
        type: string

jobs:
  collect-complete-odds:
    runs-on: ubuntu-latest
    timeout-minutes: 480  # 8 heures max pour la collecte complÃ¨te
    
    steps:
    # Ã‰tape 1: Checkout du code
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    # Ã‰tape 2: Configuration de Python
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    # Ã‰tape 3: Installation des dÃ©pendances
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests pandas numpy
        pip install --upgrade urllib3 requests

    # Ã‰tape 4: CrÃ©ation de la structure des dossiers dans data/
    - name: Create data directory structure
      run: |
        mkdir -p data
        mkdir -p data/odds
        mkdir -p data/odds/raw_data
        mkdir -p data/odds/summaries
        echo "ğŸ“ Structure crÃ©Ã©e:"
        echo "data/"
        echo "â”œâ”€â”€ odds/"
        echo "â”‚   â”œâ”€â”€ raw_data/"
        echo "â”‚   â””â”€â”€ summaries/"
        tree data/ || ls -la data/

    # Ã‰tape 5: VÃ©rification des ressources et fichiers existants
    - name: Check system resources and existing data
      run: |
        echo "=== VÃ‰RIFICATION DES RESSOURCES SYSTÃˆME ==="
        df -h
        echo ""
        echo "=== MÃ‰MOIRE DISPONIBLE ==="
        free -h
        echo ""
        echo "=== FICHIERS DE MATCHS EXISTANTS ==="
        if [ -d "data" ]; then
          find data/ -maxdepth 1 -name "*.csv" -type f | head -10 || echo "Aucun fichier CSV match"
          match_count=$(find data/ -maxdepth 1 -name '*.csv' -type f | wc -l)
          echo "Nombre de fichiers de matchs: $match_count"
        fi
        echo ""
        echo "=== FICHIERS ODDS EXISTANTS ==="
        if [ -d "data/odds/raw_data" ]; then
          odds_count=$(ls data/odds/raw_data/*.csv 2>/dev/null | wc -l)
          echo "Fichiers odds existants: $odds_count"
          ls -la data/odds/raw_data/ 2>/dev/null || echo "Dossier odds vide"
        fi

    # Ã‰tape 6: Test de connectivitÃ© API
    - name: Test API connectivity
      env:
        RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}
      run: |
        echo "ğŸ”Œ Test de connectivitÃ© API Football..."
        python3 -c "
import requests
import os
import json

headers = {
    'x-rapidapi-host': 'api-football-v1.p.rapidapi.com',
    'x-rapidapi-key': os.environ['RAPIDAPI_KEY']
}

try:
    print('ğŸ”„ Test de connexion...')
    response = requests.get(
        'https://api-football-v1.p.rapidapi.com/v3/status', 
        headers=headers, 
        timeout=10
    )
    
    if response.status_code == 200:
        data = response.json()
        print('âœ… API accessible')
        
        account = data.get('account', {})
        subscription = data.get('subscription', {})
        
        print(f'ğŸ“Š Compte: {account.get(\"firstname\", \"N/A\")} {account.get(\"lastname\", \"N/A\")}')
        print(f'ğŸ“ˆ Plan: {subscription.get(\"plan\", \"N/A\")}')
        print(f'ğŸ”„ RequÃªtes/jour: {subscription.get(\"requests_limit_daily\", \"N/A\")}')
        print(f'âœ… RequÃªtes utilisÃ©es: {account.get(\"requests\", {}).get(\"current\", \"N/A\")}')
        
    else:
        print(f'âš ï¸ Status code: {response.status_code}')
        print(f'Response: {response.text[:200]}')
        
except Exception as e:
    print(f'âŒ Erreur API: {e}')
    exit(1)
"

    # Ã‰tape 7: Configuration des paramÃ¨tres de collecte
    - name: Configure collection parameters
      run: |
        echo "ğŸ¯ CONFIGURATION DE LA COLLECTE"
        echo "LEAGUE_FILTER=${{ github.event.inputs.league_filter || '' }}" >> $GITHUB_ENV
        echo "BATCH_SIZE=${{ github.event.inputs.batch_size || '25' }}" >> $GITHUB_ENV
        
        echo "ParamÃ¨tres sÃ©lectionnÃ©s:"
        echo "  ğŸ“‹ Filtrage ligues: '${{ github.event.inputs.league_filter || 'TOUTES LES LIGUES' }}'"
        echo "  ğŸ“¦ Taille batch: ${{ github.event.inputs.batch_size || '25' }} matchs"
        echo "  ğŸ“ Destination: data/odds/"
        echo "  ğŸ¯ Objectif: TOUS les bookmakers et marchÃ©s"

    # Ã‰tape 8: PrÃ©paration du script avec filtrage dynamique
    - name: Prepare collection script with filtering
      run: |
        if [ ! -z "$LEAGUE_FILTER" ]; then
          echo "ğŸ”§ Application du filtrage par ligues: $LEAGUE_FILTER"
          cat > filter_script.py << 'EOF'
import os

# Lire le script original
with open('complete_football_odds_collector.py', 'r', encoding='utf-8') as f:
    content = f.read()

# RÃ©cupÃ©rer le filtre depuis l'environnement
league_filter = os.environ.get('LEAGUE_FILTER', '').strip()

if league_filter:
    # Parser les ligues demandÃ©es
    selected_leagues = [l.strip().upper() for l in league_filter.split(',') if l.strip()]
    print(f'ğŸ¯ Ligues sÃ©lectionnÃ©es: {selected_leagues}')
    
    # CrÃ©er le code de filtrage Ã  injecter
    filter_code = f'''
        # Filtrage dynamique des ligues (depuis GitHub Actions)
        original_leagues = len(self.all_leagues)
        filtered_leagues = {selected_leagues}
        self.all_leagues = {{k: v for k, v in self.all_leagues.items() if k in filtered_leagues}}
        logger.info(f"ğŸ¯ Filtrage activÃ©: {{len(self.all_leagues)}}/{{original_leagues}} ligues sÃ©lectionnÃ©es")
        logger.info(f"ğŸ“‹ Ligues Ã  traiter: {{list(self.all_leagues.keys())}}")
        '''
    
    # Injecter le code aprÃ¨s l'initialisation des ligues
    if '# Saisons Ã  analyser' in content:
        content = content.replace(
            '# Saisons Ã  analyser',
            filter_code + '\n        # Saisons Ã  analyser'
        )
        print('âœ… Filtrage injectÃ© avec succÃ¨s')
    else:
        print('âš ï¸ Point d\'injection non trouvÃ© - utilisation du script original')
    
    # Sauvegarder le script modifiÃ©
    with open('complete_football_odds_collector_filtered.py', 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f'âœ… Script personnalisÃ© crÃ©Ã©: complete_football_odds_collector_filtered.py')
else:
    print('â„¹ï¸ Aucun filtrage demandÃ©')
EOF
          python3 filter_script.py
        else
          echo "â„¹ï¸ Pas de filtrage - utilisation du script original"
          cp complete_football_odds_collector.py complete_football_odds_collector_filtered.py
        fi

    # Ã‰tape 9: ExÃ©cution de la collecte complÃ¨te des odds
    - name: Run complete football odds collection
      env:
        RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}
      run: |
        echo "ğŸš€ === DÃ‰BUT DE LA COLLECTE COMPLÃˆTE DES ODDS ==="
        echo "ğŸ“… DÃ©marrage: $(date '+%Y-%m-%d %H:%M:%S UTC')"
        echo "ğŸ¯ Mode: Collecte manuelle complÃ¨te"
        echo "ğŸ“ Destination: data/odds/"
        echo "ğŸ”„ Script: complete_football_odds_collector_filtered.py"
        echo ""
        
        # Lancement avec capture complÃ¨te des logs
        python complete_football_odds_collector_filtered.py 2>&1 | tee collection_output.log
        
        # Capturer le code de sortie
        exit_code=${PIPESTATUS[0]}
        
        echo ""
        echo "ğŸ“… Fin d'exÃ©cution: $(date '+%Y-%m-%d %H:%M:%S UTC')"
        echo "ğŸ”¢ Code de sortie: $exit_code"
        
        if [ $exit_code -ne 0 ]; then
          echo "âŒ La collecte s'est terminÃ©e avec des erreurs"
        else
          echo "âœ… Collecte terminÃ©e avec succÃ¨s"
        fi

    # Ã‰tape 10: Analyse dÃ©taillÃ©e des donnÃ©es collectÃ©es
    - name: Analyze collected odds data
      run: |
        echo "=== ANALYSE DES DONNÃ‰ES COLLECTÃ‰ES ==="
        echo "ğŸ“… Analyse effectuÃ©e le: $(date '+%Y-%m-%d %H:%M:%S UTC')"
        echo ""
        
        # VÃ©rifier la structure crÃ©Ã©e
        if [ -d "data/odds" ]; then
          echo "âœ… Dossier principal odds crÃ©Ã©: data/odds/"
          
          # Analyser les donnÃ©es brutes
          if [ -d "data/odds/raw_data" ]; then
            echo ""
            echo "ğŸ“Š === DONNÃ‰ES BRUTES COLLECTÃ‰ES ==="
            
            raw_files=(data/odds/raw_data/*.csv)
            if [ -e "${raw_files[0]}" ]; then
              total_files=0
              total_size=0
              total_lines=0
              
              echo "Liste des fichiers gÃ©nÃ©rÃ©s:"
              for file in data/odds/raw_data/*.csv; do
                if [ -f "$file" ]; then
                  filename=$(basename "$file")
                  lines=$(($(wc -l < "$file") - 1))  # Exclure l'en-tÃªte
                  size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo "0")
                  size_mb=$(python3 -c "print(f'{$size/1024/1024:.2f}')")
                  
                  echo "  ğŸ“„ $filename"
                  echo "      ğŸ“Š Cotes: $lines"
                  echo "      ğŸ’¾ Taille: ${size_mb}MB"
                  echo ""
                  
                  total_files=$((total_files + 1))
                  total_lines=$((total_lines + lines))
                  total_size=$((total_size + size))
                fi
              done
              
              total_size_mb=$(python3 -c "print(f'{$total_size/1024/1024:.2f}')")
              
              echo "ğŸ“ˆ === RÃ‰SUMÃ‰ GLOBAL ==="
              echo "  ğŸ“ Fichiers gÃ©nÃ©rÃ©s: $total_files"
              echo "  ğŸ² Total cotes collectÃ©es: $total_lines"
              echo "  ğŸ’¾ Taille totale: ${total_size_mb}MB"
              
            else
              echo "âš ï¸ Aucun fichier CSV gÃ©nÃ©rÃ© dans raw_data/"
            fi
          fi
          
          # Analyser les rÃ©sumÃ©s
          if [ -d "data/odds/summaries" ]; then
            echo ""
            echo "ğŸ“ˆ === RÃ‰SUMÃ‰S ANALYTIQUES ==="
            summary_files=(data/odds/summaries/*.csv)
            if [ -e "${summary_files[0]}" ]; then
              summary_count=$(ls data/odds/summaries/*.csv 2>/dev/null | wc -l)
              echo "ğŸ“Š Fichiers de rÃ©sumÃ© gÃ©nÃ©rÃ©s: $summary_count"
              ls -la data/odds/summaries/ | head -10
            else
              echo "âš ï¸ Aucun fichier de rÃ©sumÃ© gÃ©nÃ©rÃ©"
            fi
          fi
          
          # VÃ©rifier les mÃ©tadonnÃ©es
          if [ -f "data/odds/collection_metadata.json" ]; then
            echo ""
            echo "ğŸ“„ === MÃ‰TADONNÃ‰ES DE COLLECTE ==="
            echo "Extrait des mÃ©tadonnÃ©es:"
            head -30 data/odds/collection_metadata.json | python3 -m json.tool 2>/dev/null || head -30 data/odds/collection_metadata.json
          fi
          
        else
          echo "âŒ Dossier data/odds/ non crÃ©Ã©"
        fi
        
        # Afficher les derniers logs
        echo ""
        echo "ğŸ“ === LOGS RÃ‰CENTS ==="
        if [ -f "football_odds.log" ]; then
          echo "DerniÃ¨res 30 lignes du log principal:"
          tail -30 football_odds.log
        else
          echo "âš ï¸ Fichier football_odds.log non trouvÃ©"
        fi

    # Ã‰tape 11: StratÃ©gie intelligente de commit (gestion des gros fichiers)
    - name: Smart commit and push strategy
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action - Odds Collector"
        
        echo "ğŸ” === ANALYSE DES FICHIERS POUR COMMIT ==="
        
        # Toujours ajouter les petits fichiers
        git add data/odds/summaries/*.csv 2>/dev/null && echo "âœ… RÃ©sumÃ©s ajoutÃ©s" || echo "â„¹ï¸ Aucun rÃ©sumÃ©"
        git add data/odds/collection_metadata.json 2>/dev/null && echo "âœ… MÃ©tadonnÃ©es ajoutÃ©es" || echo "â„¹ï¸ Pas de mÃ©tadonnÃ©es"
        git add football_odds.log 2>/dev/null && echo "âœ… Log principal ajoutÃ©" || echo "â„¹ï¸ Pas de log"
        git add collection_output.log 2>/dev/null && echo "âœ… Log de collecte ajoutÃ©" || echo "â„¹ï¸ Pas de log de collecte"
        
        # Gestion intelligente des fichiers de donnÃ©es volumineux
        large_files_count=0
        small_files_count=0
        total_data_size=0
        
        echo ""
        echo "ğŸ“Š Analyse des fichiers de donnÃ©es:"
        
        if [ -d "data/odds/raw_data" ]; then
          for file in data/odds/raw_data/*.csv; do
            if [ -f "$file" ]; then
              size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo "0")
              size_mb=$(python3 -c "print(f'{$size/1024/1024:.1f}')")
              filename=$(basename "$file")
              
              # Seuil: 75MB pour GitHub
              if (( $(python3 -c "print($size > 75000000)") )); then
                echo "ğŸ“Š Fichier volumineux (${size_mb}MB): $filename"
                large_files_count=$((large_files_count + 1))
                
                # CrÃ©er un rÃ©sumÃ© pour les gros fichiers
                lines=$(($(wc -l < "$file") - 1))
                echo "$filename,$lines,${size_mb},$(date -Iseconds)" >> "data/odds/large_files_summary.csv"
                
              else
                echo "âœ… Fichier standard (${size_mb}MB): $filename"
                git add "$file"
                small_files_count=$((small_files_count + 1))
              fi
              
              total_data_size=$((total_data_size + size))
            fi
          done
          
          # Ajouter le rÃ©sumÃ© des gros fichiers s'il existe
          if [ -f "data/odds/large_files_summary.csv" ]; then
            echo "league_file,total_odds,file_size_mb,created_at" > temp_summary.csv
            cat "data/odds/large_files_summary.csv" >> temp_summary.csv
            mv temp_summary.csv "data/odds/large_files_summary.csv"
            git add "data/odds/large_files_summary.csv"
            echo "ğŸ“‹ RÃ©sumÃ© des gros fichiers crÃ©Ã©"
          fi
        fi
        
        total_size_mb=$(python3 -c "print(f'{$total_data_size/1024/1024:.1f}')")
        
        echo ""
        echo "ğŸ“ˆ === BILAN COMMIT ==="
        echo "  ğŸ“ Fichiers standards ajoutÃ©s: $small_files_count"
        echo "  ğŸ“Š Fichiers volumineux exclus: $large_files_count"
        echo "  ğŸ’¾ Taille totale donnÃ©es: ${total_size_mb}MB"
        
        # VÃ©rifier s'il y a des changements Ã  committer
        if git diff --staged --quiet; then
          echo ""
          echo "â„¹ï¸ Aucun changement dÃ©tectÃ© - repository dÃ©jÃ  Ã  jour"
        else
          echo ""
          echo "ğŸ”„ Nouveaux donnÃ©es odds dÃ©tectÃ©es - prÃ©paration du commit..."
          
          # Compter les fichiers modifiÃ©s
          modified_files=$(git diff --staged --name-only | wc -l)
          
          # Message de commit dÃ©taillÃ© avec Ã©mojis
          commit_message="ğŸ² Collecte complÃ¨te odds (manuel) - $(date '+%Y-%m-%d %H:%M')

ğŸ“Š RÃ©sumÃ© de la collecte:
  â€¢ Fichiers modifiÃ©s: $modified_files
  â€¢ Fichiers standards: $small_files_count
  â€¢ Fichiers volumineux: $large_files_count (rÃ©sumÃ©s)
  â€¢ Taille totale: ${total_size_mb}MB
  â€¢ PÃ©riode: 365 derniers jours
  â€¢ Objectif: TOUS bookmakers et marchÃ©s
  â€¢ Destination: data/odds/

ğŸ¤– Collecte manuelle via GitHub Actions
ğŸ¯ Filtrage: ${{ github.event.inputs.league_filter || 'Toutes les ligues' }}"
          
          git commit -m "$commit_message"
          git push
          
          echo "âœ… DonnÃ©es odds committÃ©es et poussÃ©es vers le repository"
        fi

    # Ã‰tape 12: Upload des artifacts (fichiers volumineux + logs)
    - name: Upload comprehensive artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: complete-odds-collection-${{ github.run_number }}
        path: |
          data/odds/raw_data/*.csv
          data/odds/summaries/*.csv
          data/odds/collection_metadata.json
          data/odds/large_files_summary.csv
          football_odds.log
          collection_output.log
        retention-days: 30
        if-no-files-found: warn

    # Ã‰tape 13: Rapport final complet et notifications
    - name: Generate final comprehensive report
      if: always()
      run: |
        echo ""
        echo "ğŸ‰ === RAPPORT FINAL DE LA COLLECTE COMPLÃˆTE ==="
        echo "ğŸ“… TerminÃ© le: $(date '+%Y-%m-%d %H:%M:%S UTC')"
        echo ""
        
        # Statut global
        if [ "${{ job.status }}" = "success" ]; then
          echo "âœ… STATUT GLOBAL: SUCCÃˆS COMPLET"
          status_emoji="âœ…"
        else
          echo "âš ï¸ STATUT GLOBAL: TERMINÃ‰ AVEC AVERTISSEMENTS"
          status_emoji="âš ï¸"
        fi
        
        echo ""
        echo "ğŸ“Š === BILAN DE LA COLLECTE ==="
        
        # Compter les rÃ©sultats
        if [ -d "data/odds/raw_data" ]; then
          data_files=$(ls data/odds/raw_data/*.csv 2>/dev/null | wc -l)
          echo "  ğŸ“ Fichiers de donnÃ©es: $data_files"
          
          # Calculer le total de cotes
          total_odds=0
          for file in data/odds/raw_data/*.csv; do
            if [ -f "$file" ]; then
              lines=$(($(wc -l < "$file") - 1))
              total_odds=$((total_odds + lines))
            fi
          done
          echo "  ğŸ² Total cotes collectÃ©es: $total_odds"
        else
          echo "  ğŸ“ Fichiers de donnÃ©es: 0"
          echo "  ğŸ² Total cotes collectÃ©es: 0"
        fi
        
        if [ -d "data/odds/summaries" ]; then
          summary_files=$(ls data/odds/summaries/*.csv 2>/dev/null | wc -l)
          echo "  ğŸ“ˆ Fichiers de rÃ©sumÃ©s: $summary_files"
        else
          echo "  ğŸ“ˆ Fichiers de rÃ©sumÃ©s: 0"
        fi
        
        # Taille des donnÃ©es
        if [ -d "data/odds" ]; then
          total_size=$(du -sh data/odds 2>/dev/null | cut -f1 || echo "0B")
          echo "  ğŸ’¾ Taille totale: $total_size"
        fi
        
        echo ""
        echo "ğŸ“¦ === INFORMATIONS ARTIFACTS ==="
        echo "  ğŸ·ï¸ Nom: complete-odds-collection-${{ github.run_number }}"
        echo "  ğŸ“‹ Contenu: Tous fichiers de donnÃ©es + logs"
        echo "  â° RÃ©tention: 30 jours"
        echo "  ğŸ”— AccÃ¨s: Actions â†’ Run #${{ github.run_number }} â†’ Artifacts"
        
        echo ""
        echo "ğŸ—‚ï¸ === STRUCTURE FINALE DES DONNÃ‰ES ==="
        echo "data/"
        echo "â”œâ”€â”€ [fichiers matchs existants].csv"
        echo "â””â”€â”€ odds/"
        echo "    â”œâ”€â”€ raw_data/"
        echo "    â”‚   â””â”€â”€ [LIGUE]_complete_odds.csv"
        echo "    â”œâ”€â”€ summaries/"
        echo "    â”‚   â”œâ”€â”€ [LIGUE]_bookmaker_summary.csv"
        echo "    â”‚   â””â”€â”€ [LIGUE]_bet_types_summary.csv"
        echo "    â”œâ”€â”€ collection_metadata.json"
        echo "    â””â”€â”€ large_files_summary.csv (si applicable)"
        
        echo ""
        echo "ğŸ’¡ === INFORMATIONS UTILES ==="
        echo "  ğŸ¯ PÃ©riode couverte: 365 derniers jours"
        echo "  ğŸ“Š DonnÃ©es: TOUS bookmakers et marchÃ©s disponibles"
        echo "  ğŸ”„ Type: Collecte manuelle complÃ¨te"
        echo "  ğŸ“ Organisation: DonnÃ©es dans data/odds/"
        echo "  ğŸ” Filtrage appliquÃ©: ${{ github.event.inputs.league_filter || 'Aucun (toutes les ligues)' }}"
        
        echo ""
        echo "$status_emoji COLLECTE COMPLÃˆTE TERMINÃ‰E!"
        echo "   Les cotes historiques ont Ã©tÃ© rÃ©cupÃ©rÃ©es et organisÃ©es"
        echo "   dans le dossier data/odds/ selon la structure dÃ©finie."
        echo ""
        echo "ğŸš€ Prochaine Ã©tape: Analyser les donnÃ©es dans data/odds/" 
