# .github/workflows/complete_football_odds_collection.yml
name: Complete Football Odds Collection (TOUS les marchÃ©s et bookmakers)

# DÃ©clenchement manuel + automatique hebdomadaire
on:
  schedule:
    - cron: '0 6 * * 6'  # Tous les samedis Ã  6h00 UTC
  workflow_dispatch:  # Permet de lancer manuellement le workflow
    inputs:
      league_filter:
        description: 'Filtrer par ligue (optionnel, ex: ENG1,FRA1) - laissez vide pour toutes'
        required: false
        default: ''
      batch_size:
        description: 'Taille des batches (dÃ©faut: 25)'
        required: false
        default: '25'

jobs:
  collect-complete-odds:
    runs-on: ubuntu-latest
    timeout-minutes: 480  # 8 heures max pour la collecte complÃ¨te
    
    steps:
    # Ã‰tape 1: Checkout du code
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0  # RÃ©cupÃ¨re tout l'historique

    # Ã‰tape 2: Configuration de Python
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    # Ã‰tape 3: Installation des dÃ©pendances
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests pandas numpy
        pip install --upgrade urllib3 requests

    # Ã‰tape 4: CrÃ©ation des dossiers nÃ©cessaires
    - name: Create directories
      run: |
        mkdir -p data
        mkdir -p complete_odds_data
        mkdir -p complete_odds_data/raw_data
        mkdir -p complete_odds_data/summaries

    # Ã‰tape 5: VÃ©rification de l'espace disque et des fichiers existants
    - name: Check system resources and existing files
      run: |
        echo "=== VÃ‰RIFICATION DES RESSOURCES SYSTÃˆME ==="
        df -h
        echo ""
        echo "=== MÃ‰MOIRE DISPONIBLE ==="
        free -h
        echo ""
        echo "=== FICHIERS EXISTANTS (MATCHS) ==="
        if [ -d "data" ]; then
          ls -la data/ || echo "Dossier data vide"
          echo "Nombre de fichiers CSV matchs: $(ls data/*.csv 2>/dev/null | wc -l)"
        fi
        echo ""
        echo "=== FICHIERS EXISTANTS (ODDS) ==="
        if [ -d "complete_odds_data/raw_data" ]; then
          ls -la complete_odds_data/raw_data/ || echo "Dossier odds vide"
          echo "Nombre de fichiers CSV odds: $(ls complete_odds_data/raw_data/*.csv 2>/dev/null | wc -l)"
        fi

    # Ã‰tape 6: Test de connectivitÃ© API
    - name: Test API connectivity
      env:
        RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}
      run: |
        echo "ðŸ”Œ Test de connectivitÃ© API..."
        python -c "
import requests
import os
headers = {
    'x-rapidapi-host': 'api-football-v1.p.rapidapi.com',
    'x-rapidapi-key': os.environ['RAPIDAPI_KEY']
}
try:
    response = requests.get('https://api-football-v1.p.rapidapi.com/v3/status', headers=headers, timeout=10)
    if response.status_code == 200:
        data = response.json()
        print('âœ… API accessible')
        print(f'Account: {data.get(\"account\", {})}')
        print(f'Subscription: {data.get(\"subscription\", {})}')
    else:
        print(f'âš ï¸ Status code: {response.status_code}')
except Exception as e:
    print(f'âŒ Erreur API: {e}')
"

    # Ã‰tape 7: Configuration des paramÃ¨tres
    - name: Configure collection parameters
      run: |
        echo "LEAGUE_FILTER=${{ github.event.inputs.league_filter || '' }}" >> $GITHUB_ENV
        echo "BATCH_SIZE=${{ github.event.inputs.batch_size || '25' }}" >> $GITHUB_ENV
        echo "ðŸŽ¯ ParamÃ¨tres de collecte:"
        echo "  - Filtrage ligues: '${{ github.event.inputs.league_filter || 'TOUTES' }}'"
        echo "  - Taille batch: ${{ github.event.inputs.batch_size || '25' }}"

    # Ã‰tape 8: Modification dynamique du script si filtrage
    - name: Prepare collection script
      run: |
        if [ ! -z "$LEAGUE_FILTER" ]; then
          echo "ðŸ”§ Configuration du filtrage par ligue: $LEAGUE_FILTER"
          python -c "
import os
# Lire le contenu du script
with open('complete_football_odds_collector.py', 'r') as f:
    content = f.read()

# Modifier la configuration des ligues si filtrage demandÃ©
league_filter = os.environ.get('LEAGUE_FILTER', '')
if league_filter:
    leagues = [l.strip() for l in league_filter.split(',') if l.strip()]
    print(f'Filtrage activÃ© pour: {leagues}')
    
    # Injecter le filtrage dans le script
    filter_code = f'''
        # Filtrage dynamique des ligues (depuis GitHub Actions)
        if True:  # Filtrage activÃ©
            filtered_leagues = {leagues}
            self.all_leagues = {{k: v for k, v in self.all_leagues.items() if k in filtered_leagues}}
            logger.info(f\"ðŸŽ¯ Filtrage activÃ©: {{len(self.all_leagues)}} ligues sÃ©lectionnÃ©es: {{list(self.all_leagues.keys())}}\")
        '''
    
    # Injecter aprÃ¨s l'initialisation des ligues
    content = content.replace(
        \"# Saisons Ã  analyser\",
        filter_code + \"\\n        # Saisons Ã  analyser\"
    )
    
    # Sauvegarder le script modifiÃ©
    with open('complete_football_odds_collector_filtered.py', 'w') as f:
        f.write(content)
    
    print('âœ… Script filtrÃ© crÃ©Ã©: complete_football_odds_collector_filtered.py')
else:
    print('â„¹ï¸ Aucun filtrage - utilisation du script original')
"
        else
          echo "â„¹ï¸ Pas de filtrage - copie du script original"
          cp complete_football_odds_collector.py complete_football_odds_collector_filtered.py
        fi

    # Ã‰tape 9: ExÃ©cution de la collecte complÃ¨te des odds
    - name: Run complete football odds collection
      env:
        RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}
      run: |
        echo "ðŸš€ DÃ‰BUT DE LA COLLECTE COMPLÃˆTE DES ODDS"
        echo "ðŸ“… Date de dÃ©but: $(date)"
        echo "ðŸŽ¯ Objectif: TOUS les bookmakers, TOUS les marchÃ©s"
        echo ""
        
        # Lancement avec gestion d'erreurs
        python complete_football_odds_collector_filtered.py 2>&1 | tee collection_output.log
        
        echo ""
        echo "ðŸ“… Date de fin: $(date)"

    # Ã‰tape 10: VÃ©rification des donnÃ©es collectÃ©es
    - name: Verify and analyze collected odds data
      run: |
        echo "=== VÃ‰RIFICATION DES DONNÃ‰ES COLLECTÃ‰ES ==="
        echo "ðŸ“… VÃ©rification effectuÃ©e le: $(date)"
        echo ""
        
        # VÃ©rifier le dossier principal
        if [ -d "complete_odds_data" ]; then
          echo "âœ… Dossier principal odds crÃ©Ã©"
          
          # Analyser les fichiers de donnÃ©es brutes
          if [ -d "complete_odds_data/raw_data" ]; then
            echo ""
            echo "ðŸ“Š FICHIERS DE DONNÃ‰ES BRUTES:"
            raw_files=(complete_odds_data/raw_data/*.csv)
            if [ -e "${raw_files[0]}" ]; then
              total_files=0
              total_size=0
              total_lines=0
              
              for file in complete_odds_data/raw_data/*.csv; do
                if [ -f "$file" ]; then
                  filename=$(basename "$file")
                  lines=$(($(wc -l < "$file") - 1))  # Exclure l'en-tÃªte
                  size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo "0")
                  size_mb=$(echo "scale=2; $size / 1024 / 1024" | bc -l 2>/dev/null || echo "0")
                  
                  echo "  ðŸ“„ $filename:"
                  echo "      - Lignes: $lines cotes"
                  echo "      - Taille: ${size_mb}MB"
                  
                  total_files=$((total_files + 1))
                  total_lines=$((total_lines + lines))
                  total_size=$((total_size + size))
                fi
              done
              
              total_size_mb=$(echo "scale=2; $total_size / 1024 / 1024" | bc -l 2>/dev/null || echo "0")
              echo ""
              echo "ðŸ“Š RÃ‰SUMÃ‰ TOTAL:"
              echo "  - Fichiers gÃ©nÃ©rÃ©s: $total_files"
              echo "  - Total cotes collectÃ©es: $total_lines"
              echo "  - Taille totale: ${total_size_mb}MB"
            else
              echo "âš ï¸ Aucun fichier CSV dans raw_data"
            fi
          fi
          
          # Analyser les rÃ©sumÃ©s
          if [ -d "complete_odds_data/summaries" ]; then
            echo ""
            echo "ðŸ“ˆ FICHIERS DE RÃ‰SUMÃ‰S:"
            summary_files=(complete_odds_data/summaries/*.csv)
            if [ -e "${summary_files[0]}" ]; then
              ls -la complete_odds_data/summaries/
            else
              echo "âš ï¸ Aucun fichier de rÃ©sumÃ© gÃ©nÃ©rÃ©"
            fi
          fi
          
          # VÃ©rifier les mÃ©tadonnÃ©es
          if [ -f "complete_odds_data/collection_metadata.json" ]; then
            echo ""
            echo "ðŸ“„ MÃ‰TADONNÃ‰ES DE COLLECTE:"
            echo "$(head -20 complete_odds_data/collection_metadata.json)"
          fi
          
        else
          echo "âŒ Dossier complete_odds_data non crÃ©Ã©"
        fi
        
        # VÃ©rifier les logs
        echo ""
        echo "ðŸ“ LOGS DE COLLECTE (derniÃ¨res lignes):"
        if [ -f "football_odds.log" ]; then
          tail -20 football_odds.log
        else
          echo "Aucun fichier de log trouvÃ©"
        fi

    # Ã‰tape 11: Gestion intelligente des commits (Ã©viter les fichiers trop gros)
    - name: Intelligent commit and push strategy
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action Bot"
        
        echo "ðŸ” Analyse des fichiers pour commit intelligent..."
        
        # Ajouter les fichiers de rÃ©sumÃ©s (toujours petits)
        git add complete_odds_data/summaries/*.csv 2>/dev/null || echo "Aucun fichier de rÃ©sumÃ©"
        git add complete_odds_data/collection_metadata.json 2>/dev/null || echo "Aucun fichier de mÃ©tadonnÃ©es"
        git add football_odds.log 2>/dev/null || echo "Aucun fichier de log"
        
        # Gestion intelligente des gros fichiers de donnÃ©es
        large_files_count=0
        small_files_count=0
        
        if [ -d "complete_odds_data/raw_data" ]; then
          for file in complete_odds_data/raw_data/*.csv; do
            if [ -f "$file" ]; then
              size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo "0")
              size_mb=$(echo "$size / 1024 / 1024" | bc -l 2>/dev/null || echo "0")
              size_mb_int=$(echo "$size_mb" | cut -d. -f1)
              
              if [ "$size_mb_int" -gt 50 ]; then
                # Fichier > 50MB : crÃ©er un rÃ©sumÃ© au lieu de commit complet
                echo "ðŸ“Š Fichier volumineux dÃ©tectÃ© (${size_mb}MB): $(basename "$file")"
                large_files_count=$((large_files_count + 1))
                
                # CrÃ©er un fichier rÃ©sumÃ© pour les gros fichiers
                echo "league_file,total_odds,file_size_mb,created_at" > "complete_odds_data/large_file_summary.csv"
                echo "$(basename "$file"),$(($(wc -l < "$file") - 1)),${size_mb},$(date -Iseconds)" >> "complete_odds_data/large_file_summary.csv"
                
              else
                # Fichier < 50MB : commit normal
                echo "âœ… Ajout fichier normal (${size_mb}MB): $(basename "$file")"
                git add "$file"
                small_files_count=$((small_files_count + 1))
              fi
            fi
          done
        fi
        
        # Ajouter le rÃ©sumÃ© des gros fichiers s'il existe
        git add complete_odds_data/large_file_summary.csv 2>/dev/null || true
        
        # VÃ©rifier s'il y a des changements Ã  committer
        if git diff --staged --quiet; then
          echo "âœ… Aucun changement dÃ©tectÃ© - donnÃ©es dÃ©jÃ  Ã  jour"
        else
          echo "ðŸŽ² Nouvelles donnÃ©es odds dÃ©tectÃ©es - commit en cours..."
          
          # Compter les fichiers modifiÃ©s
          modified_files=$(git diff --staged --name-only | wc -l)
          
          # Message de commit dÃ©taillÃ©
          commit_message="ðŸŽ² Collecte complÃ¨te odds historiques - $(date '+%Y-%m-%d %H:%M')

ðŸ“Š RÃ©sumÃ© de la collecte:
- Fichiers modifiÃ©s: $modified_files
- Petits fichiers ajoutÃ©s: $small_files_count
- Gros fichiers rÃ©sumÃ©s: $large_files_count
- PÃ©riode: 365 derniers jours
- Objectif: TOUS les bookmakers et marchÃ©s

ðŸ¤– Collecte automatique via GitHub Actions"
          
          git commit -m "$commit_message"
          git push
          
          echo "âœ… DonnÃ©es odds mises Ã  jour et poussÃ©es vers le repository"
        fi

    # Ã‰tape 12: Upload des logs et gros fichiers comme artifacts
    - name: Upload large files and logs as artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: complete-odds-collection-${{ github.run_number }}
        path: |
          complete_odds_data/raw_data/*.csv
          football_odds.log
          collection_output.log
          complete_odds_data/collection_metadata.json
        retention-days: 30

    # Ã‰tape 13: RÃ©sumÃ© final et notifications
    - name: Final summary and notification
      if: always()
      run: |
        echo ""
        echo "ðŸŽ‰ === RÃ‰SUMÃ‰ FINAL DE LA COLLECTE COMPLÃˆTE ==="
        echo "ðŸ“… ExÃ©cution terminÃ©e le: $(date)"
        echo ""
        
        # Statut de la collecte
        if [ ${{ job.status }} = "success" ]; then
          echo "âœ… STATUT: SUCCÃˆS"
        else
          echo "âŒ STATUT: Ã‰CHEC"
        fi
        
        # RÃ©sumÃ© des fichiers crÃ©Ã©s
        if [ -d "complete_odds_data/raw_data" ]; then
          file_count=$(ls complete_odds_data/raw_data/*.csv 2>/dev/null | wc -l)
          echo "ðŸ“Š Fichiers de donnÃ©es crÃ©Ã©s: $file_count"
        fi
        
        if [ -d "complete_odds_data/summaries" ]; then
          summary_count=$(ls complete_odds_data/summaries/*.csv 2>/dev/null | wc -l)
          echo "ðŸ“ˆ Fichiers de rÃ©sumÃ©s crÃ©Ã©s: $summary_count"
        fi
        
        # Espace disque utilisÃ©
        if [ -d "complete_odds_data" ]; then
          total_size=$(du -sh complete_odds_data 2>/dev/null | cut -f1 || echo "0")
          echo "ðŸ’¾ Espace total utilisÃ©: $total_size"
        fi
        
        # Informations sur les artifacts
        echo ""
        echo "ðŸ“¦ ARTIFACTS DISPONIBLES:"
        echo "  - Nom: complete-odds-collection-${{ github.run_number }}"
        echo "  - Contenu: Tous les fichiers de donnÃ©es + logs"
        echo "  - RÃ©tention: 30 jours"
        echo "  - AccÃ¨s: Actions > Artifacts de cette exÃ©cution"
        
        echo ""
        echo "ðŸŽ¯ COLLECTE COMPLÃˆTE TERMINÃ‰E!"
        echo "   Toutes les cotes historiques disponibles ont Ã©tÃ© rÃ©cupÃ©rÃ©es"
        echo "   pour la pÃ©riode de 365 derniers jours sur TOUS les marchÃ©s"
        echo "   et TOUS les bookmakers disponibles via API-Football."
