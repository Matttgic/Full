name: Complete Football Odds Collection

on:
  workflow_dispatch:
    inputs:
      league_filter:
        description: 'Filtrer par ligue (ex: ENG1,FRA1) - vide pour toutes'
        required: false
        default: ''
        type: string
      batch_size:
        description: 'Taille des batches (defaut: 25)'
        required: false
        default: '25'
        type: string

jobs:
  collect-complete-odds:
    runs-on: ubuntu-latest
    timeout-minutes: 480
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests pandas numpy
        pip install --upgrade urllib3 requests

    - name: Create data directory structure
      run: |
        mkdir -p data/odds/raw_data
        mkdir -p data/odds/summaries
        echo "Structure créée dans data/odds/"
        ls -la data/

    - name: Check system resources
      run: |
        echo "=== RESSOURCES SYSTÈME ==="
        df -h
        echo "=== MÉMOIRE ==="
        free -h
        echo "=== FICHIERS EXISTANTS ==="
        if [ -d "data" ]; then
          find data/ -maxdepth 1 -name "*.csv" -type f | head -10 || echo "Aucun CSV"
        fi
        if [ -d "data/odds/raw_data" ]; then
          ls -la data/odds/raw_data/ || echo "Dossier odds vide"
        fi

    - name: Test API connectivity
      env:
        RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}
      run: |
        echo "Test de connectivité API Football..."
        echo 'import requests' > test_api.py
        echo 'import os' >> test_api.py
        echo 'import json' >> test_api.py
        echo '' >> test_api.py
        echo 'headers = {' >> test_api.py
        echo '    "x-rapidapi-host": "api-football-v1.p.rapidapi.com",' >> test_api.py
        echo '    "x-rapidapi-key": os.environ["RAPIDAPI_KEY"]' >> test_api.py
        echo '}' >> test_api.py
        echo '' >> test_api.py
        echo 'try:' >> test_api.py
        echo '    print("Test de connexion...")' >> test_api.py
        echo '    response = requests.get(' >> test_api.py
        echo '        "https://api-football-v1.p.rapidapi.com/v3/status",' >> test_api.py
        echo '        headers=headers,' >> test_api.py
        echo '        timeout=10' >> test_api.py
        echo '    )' >> test_api.py
        echo '    if response.status_code == 200:' >> test_api.py
        echo '        data = response.json()' >> test_api.py
        echo '        print("API accessible")' >> test_api.py
        echo '        account = data.get("account", {})' >> test_api.py
        echo '        subscription = data.get("subscription", {})' >> test_api.py
        echo '        print(f"Plan: {subscription.get('"'"'plan'"'"', '"'"'N/A'"'"')}")' >> test_api.py
        echo '    else:' >> test_api.py
        echo '        print(f"Status code: {response.status_code}")' >> test_api.py
        echo 'except Exception as e:' >> test_api.py
        echo '    print(f"Erreur API: {e}")' >> test_api.py
        echo '    exit(1)' >> test_api.py
        python test_api.py

    - name: Configure collection parameters
      run: |
        echo "CONFIGURATION DE LA COLLECTE"
        echo "LEAGUE_FILTER=${{ github.event.inputs.league_filter || '' }}" >> $GITHUB_ENV
        echo "BATCH_SIZE=${{ github.event.inputs.batch_size || '25' }}" >> $GITHUB_ENV
        
        echo "Paramètres sélectionnés:"
        echo "  Filtrage ligues: '${{ github.event.inputs.league_filter || 'TOUTES' }}'"
        echo "  Taille batch: ${{ github.event.inputs.batch_size || '25' }} matchs"
        echo "  Destination: data/odds/"

    - name: Prepare collection script
      run: |
        if [ ! -z "$LEAGUE_FILTER" ]; then
          echo "Application du filtrage par ligues: $LEAGUE_FILTER"
          echo 'import os' > prepare_filter.py
          echo '' >> prepare_filter.py
          echo 'try:' >> prepare_filter.py
          echo '    with open("complete_football_odds_collector.py", "r", encoding="utf-8") as f:' >> prepare_filter.py
          echo '        content = f.read()' >> prepare_filter.py
          echo '' >> prepare_filter.py
          echo '    league_filter = os.environ.get("LEAGUE_FILTER", "").strip()' >> prepare_filter.py
          echo '' >> prepare_filter.py
          echo '    if league_filter:' >> prepare_filter.py
          echo '        selected_leagues = [l.strip().upper() for l in league_filter.split(",") if l.strip()]' >> prepare_filter.py
          echo '        print(f"Ligues sélectionnées: {selected_leagues}")' >> prepare_filter.py
          echo '' >> prepare_filter.py
          echo '        filter_code = """' >> prepare_filter.py
          echo '        # Filtrage dynamique des ligues' >> prepare_filter.py
          echo '        original_leagues = len(self.all_leagues)' >> prepare_filter.py
          echo '        filtered_leagues = """ + str(selected_leagues) + """' >> prepare_filter.py
          echo '        self.all_leagues = {k: v for k, v in self.all_leagues.items() if k in filtered_leagues}' >> prepare_filter.py
          echo '        logger.info(f"Filtrage activé: {len(self.all_leagues)}/{original_leagues} ligues")' >> prepare_filter.py
          echo '        """' >> prepare_filter.py
          echo '' >> prepare_filter.py
          echo '        if "# Saisons à analyser" in content:' >> prepare_filter.py
          echo '            content = content.replace("# Saisons à analyser", filter_code + "\n        # Saisons à analyser")' >> prepare_filter.py
          echo '            print("Filtrage injecté avec succès")' >> prepare_filter.py
          echo '        else:' >> prepare_filter.py
          echo '            print("Point d injection non trouvé")' >> prepare_filter.py
          echo '' >> prepare_filter.py
          echo '        with open("complete_football_odds_collector_filtered.py", "w", encoding="utf-8") as f:' >> prepare_filter.py
          echo '            f.write(content)' >> prepare_filter.py
          echo '' >> prepare_filter.py
          echo '        print("Script personnalisé créé")' >> prepare_filter.py
          echo '    else:' >> prepare_filter.py
          echo '        print("Aucun filtrage demandé")' >> prepare_filter.py
          echo '' >> prepare_filter.py
          echo 'except Exception as e:' >> prepare_filter.py
          echo '    print(f"Erreur: {e}")' >> prepare_filter.py
          python prepare_filter.py
        else
          echo "Pas de filtrage - utilisation du script original"
          cp complete_football_odds_collector.py complete_football_odds_collector_filtered.py
        fi

    - name: Run complete odds collection
      env:
        RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}
      run: |
        echo "DÉBUT DE LA COLLECTE COMPLÈTE DES ODDS"
        echo "Démarrage: $(date)"
        echo "Script: complete_football_odds_collector_filtered.py"
        
        python complete_football_odds_collector_filtered.py 2>&1 | tee collection_output.log
        
        exit_code=${PIPESTATUS[0]}
        echo "Fin: $(date)"
        echo "Code de sortie: $exit_code"
        
        if [ $exit_code -ne 0 ]; then
          echo "La collecte s'est terminée avec des erreurs"
        else
          echo "Collecte terminée avec succès"
        fi

    - name: Analyze collected data
      run: |
        echo "ANALYSE DES DONNÉES COLLECTÉES"
        echo "Analyse le: $(date)"
        
        if [ -d "data/odds" ]; then
          echo "Dossier odds créé: data/odds/"
          
          if [ -d "data/odds/raw_data" ]; then
            echo "DONNÉES BRUTES:"
            
            total_files=0
            total_lines=0
            
            for file in data/odds/raw_data/*.csv; do
              if [ -f "$file" ]; then
                filename=$(basename "$file")
                lines=$(wc -l < "$file")
                lines=$((lines - 1))
                size=$(du -h "$file" | cut -f1)
                
                echo "  $filename: $lines cotes ($size)"
                
                total_files=$((total_files + 1))
                total_lines=$((total_lines + lines))
              fi
            done
            
            echo "RÉSUMÉ GLOBAL:"
            echo "  Fichiers générés: $total_files"
            echo "  Total cotes: $total_lines"
          fi
          
          if [ -d "data/odds/summaries" ]; then
            echo "RÉSUMÉS:"
            summary_count=$(ls data/odds/summaries/*.csv 2>/dev/null | wc -l)
            echo "Fichiers de résumé: $summary_count"
            ls -la data/odds/summaries/ 2>/dev/null || echo "Aucun résumé"
          fi
          
          if [ -f "data/odds/collection_metadata.json" ]; then
            echo "MÉTADONNÉES:"
            head -20 data/odds/collection_metadata.json
          fi
          
        else
          echo "Dossier data/odds/ non créé"
        fi
        
        echo "LOGS RÉCENTS:"
        if [ -f "football_odds.log" ]; then
          tail -20 football_odds.log
        else
          echo "Fichier football_odds.log non trouvé"
        fi

    - name: Smart commit strategy
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action - Odds Collector"
        
        echo "ANALYSE DES FICHIERS POUR COMMIT"
        
        # Ajouter les petits fichiers
        git add data/odds/summaries/*.csv 2>/dev/null || echo "Aucun résumé"
        git add data/odds/collection_metadata.json 2>/dev/null || echo "Pas de métadonnées"
        git add football_odds.log 2>/dev/null || echo "Pas de log"
        git add collection_output.log 2>/dev/null || echo "Pas de log collecte"
        
        # Gestion des gros fichiers
        large_files_count=0
        small_files_count=0
        
        echo "Analyse des fichiers de données:"
        
        if [ -d "data/odds/raw_data" ]; then
          for file in data/odds/raw_data/*.csv; do
            if [ -f "$file" ]; then
              size=$(stat -c%s "$file" 2>/dev/null || stat -f%z "$file" 2>/dev/null || echo "0")
              size_mb=$(python -c "print(f'{$size/1024/1024:.1f}')")
              filename=$(basename "$file")
              
              # Seuil: 75MB pour GitHub
              if [ $size -gt 75000000 ]; then
                echo "Fichier volumineux (${size_mb}MB): $filename"
                large_files_count=$((large_files_count + 1))
                
                lines=$(wc -l < "$file")
                lines=$((lines - 1))
                echo "$filename,$lines,${size_mb},$(date -Iseconds)" >> "data/odds/large_files_summary.csv"
                
              else
                echo "Fichier standard (${size_mb}MB): $filename"
                git add "$file"
                small_files_count=$((small_files_count + 1))
              fi
            fi
          done
          
          if [ -f "data/odds/large_files_summary.csv" ]; then
            echo "league_file,total_odds,file_size_mb,created_at" > temp_summary.csv
            cat "data/odds/large_files_summary.csv" >> temp_summary.csv
            mv temp_summary.csv "data/odds/large_files_summary.csv"
            git add "data/odds/large_files_summary.csv"
            echo "Résumé des gros fichiers créé"
          fi
        fi
        
        echo "BILAN COMMIT:"
        echo "  Fichiers standards: $small_files_count"
        echo "  Fichiers volumineux exclus: $large_files_count"
        
        if git diff --staged --quiet; then
          echo "Aucun changement - repository à jour"
        else
          echo "Nouveaux données détectées - commit..."
          
          modified_files=$(git diff --staged --name-only | wc -l)
          
          commit_message="Collecte complète odds - $(date '+%Y-%m-%d %H:%M')

Résumé:
  • Fichiers modifiés: $modified_files
  • Fichiers standards: $small_files_count
  • Fichiers volumineux: $large_files_count (résumés)
  • Période: 365 derniers jours
  • Destination: data/odds/

Collecte manuelle via GitHub Actions
Filtrage: ${{ github.event.inputs.league_filter || 'Toutes les ligues' }}"
          
          git commit -m "$commit_message"
          git push
          
          echo "Données committées et poussées"
        fi

    - name: Upload artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: complete-odds-collection-${{ github.run_number }}
        path: |
          data/odds/raw_data/*.csv
          data/odds/summaries/*.csv
          data/odds/collection_metadata.json
          data/odds/large_files_summary.csv
          football_odds.log
          collection_output.log
        retention-days: 30
        if-no-files-found: warn

    - name: Final report
      if: always()
      run: |
        echo ""
        echo "RAPPORT FINAL DE LA COLLECTE COMPLÈTE"
        echo "Terminé le: $(date)"
        
        if [ "${{ job.status }}" = "success" ]; then
          echo "STATUT: SUCCÈS COMPLET"
          status_emoji="✅"
        else
          echo "STATUT: TERMINÉ AVEC AVERTISSEMENTS"
          status_emoji="⚠️"
        fi
        
        echo "BILAN:"
        
        if [ -d "data/odds/raw_data" ]; then
          data_files=$(ls data/odds/raw_data/*.csv 2>/dev/null | wc -l)
          echo "  Fichiers de données: $data_files"
          
          total_odds=0
          for file in data/odds/raw_data/*.csv; do
            if [ -f "$file" ]; then
              lines=$(wc -l < "$file")
              lines=$((lines - 1))
              total_odds=$((total_odds + lines))
            fi
          done
          echo "  Total cotes: $total_odds"
        else
          echo "  Fichiers de données: 0"
          echo "  Total cotes: 0"
        fi
        
        if [ -d "data/odds/summaries" ]; then
          summary_files=$(ls data/odds/summaries/*.csv 2>/dev/null | wc -l)
          echo "  Fichiers résumés: $summary_files"
        else
          echo "  Fichiers résumés: 0"
        fi
        
        if [ -d "data/odds" ]; then
          total_size=$(du -sh data/odds 2>/dev/null | cut -f1 || echo "0B")
          echo "  Taille totale: $total_size"
        fi
        
        echo "ARTIFACTS:"
        echo "  Nom: complete-odds-collection-${{ github.run_number }}"
        echo "  Rétention: 30 jours"
        
        echo "STRUCTURE:"
        echo "data/"
        echo "└── odds/"
        echo "    ├── raw_data/"
        echo "    ├── summaries/"
        echo "    ├── collection_metadata.json"
        echo "    └── large_files_summary.csv"
        
        echo "INFOS:"
        echo "  Période: 365 derniers jours"
        echo "  Type: Collecte manuelle complète"
        echo "  Filtrage: ${{ github.event.inputs.league_filter || 'Aucun' }}"
        
        echo "$status_emoji COLLECTE TERMINÉE!"
        echo "Données dans data/odds/" 
