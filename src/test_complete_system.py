#!/usr/bin/env python3
"""
Test complet du syst√®me de pr√©dictions de football
D√©montre toutes les fonctionnalit√©s du workflow
"""

import os
import sys
import logging
from datetime import datetime

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_demo_workflow():
    """Test du workflow de d√©monstration"""
    logger.info("üé≠ === TEST DU WORKFLOW D√âMONSTRATION ===")
    
    try:
        from demo_predictions import DemoPredictionsWorkflow
        
        workflow = DemoPredictionsWorkflow()
        workflow.run_demo_workflow()
        
        return True
    except Exception as e:
        logger.error(f"‚ùå Erreur workflow d√©mo: {e}")
        return False

def test_analyzer():
    """Test de l'analyseur de pr√©dictions"""
    logger.info("üìä === TEST DE L'ANALYSEUR ===")
    
    try:
        from analysis.predictions_analyzer import PredictionsAnalyzer
        import pandas as pd
        
        analyzer = PredictionsAnalyzer()
        analyzer.historical_file = 'data/predictions/demo_historical_predictions.csv'
        
        # V√©rifier que le fichier existe
        if not os.path.exists(analyzer.historical_file):
            logger.error("‚ùå Fichier de d√©mo non trouv√©")
            return False
        
        # Charger et analyser
        df = analyzer.load_historical_data()
        if df.empty:
            logger.error("‚ùå Aucune donn√©e charg√©e")
            return False
        
        logger.info(f"‚úÖ {len(df)} pr√©dictions charg√©es")
        
        # Tests des fonctions d'analyse
        analyzer.analyze_by_league(df)
        analyzer.analyze_similarity_distribution(df)
        analyzer.find_high_confidence_predictions(df, min_confidence=75.0)
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur analyseur: {e}")
        return False

def test_data_integrity():
    """Test de l'int√©grit√© des donn√©es"""
    logger.info("üîç === TEST INT√âGRIT√â DES DONN√âES ===")
    
    # V√©rifier les donn√©es historiques
    odds_dir = 'data/odds/raw_data'
    if not os.path.exists(odds_dir):
        logger.error(f"‚ùå Dossier des cotes manquant: {odds_dir}")
        return False
    
    odds_files = [f for f in os.listdir(odds_dir) if f.endswith('.csv')]
    logger.info(f"‚úÖ {len(odds_files)} fichiers de cotes trouv√©s")
    
    if len(odds_files) == 0:
        logger.error("‚ùå Aucun fichier de cotes")
        return False
    
    # V√©rifier les pr√©dictions g√©n√©r√©es
    predictions_dir = 'data/predictions'
    if os.path.exists(predictions_dir):
        pred_files = [f for f in os.listdir(predictions_dir) if f.endswith('.csv')]
        logger.info(f"‚úÖ {len(pred_files)} fichiers de pr√©dictions trouv√©s")
    
    return True

def test_csv_format():
    """Test du format des CSV g√©n√©r√©s"""
    logger.info("üìã === TEST FORMAT CSV ===")
    
    try:
        import pandas as pd
        
        demo_file = 'data/predictions/demo_daily_2025-08-22.csv'
        if os.path.exists(demo_file):
            df = pd.read_csv(demo_file)
            
            logger.info(f"‚úÖ CSV charg√©: {len(df)} lignes, {len(df.columns)} colonnes")
            
            # V√©rifier les colonnes essentielles
            essential_cols = [
                'date', 'home_team', 'away_team', 'league_name', 
                'total_bet_types_analyzed'
            ]
            
            missing_cols = [col for col in essential_cols if col not in df.columns]
            if missing_cols:
                logger.error(f"‚ùå Colonnes manquantes: {missing_cols}")
                return False
            
            logger.info("‚úÖ Toutes les colonnes essentielles pr√©sentes")
            
            # V√©rifier les colonnes de similarit√©
            similarity_cols = [col for col in df.columns if col.endswith('_similarity_pct')]
            confidence_cols = [col for col in df.columns if col.endswith('_confidence')]
            
            logger.info(f"‚úÖ {len(similarity_cols)} colonnes de similarit√©")
            logger.info(f"‚úÖ {len(confidence_cols)} colonnes de confiance")
            
            # V√©rifier les valeurs de similarit√©
            for col in similarity_cols[:5]:  # Tester les 5 premi√®res
                values = df[col].dropna()
                if len(values) > 0:
                    valid_values = values[(values >= 0) & (values <= 100)]
                    if len(valid_values) != len(values):
                        logger.warning(f"‚ö†Ô∏è Valeurs invalides dans {col}")
                    else:
                        logger.info(f"‚úÖ {col}: valeurs valides (0-100%)")
            
            return True
        else:
            logger.error(f"‚ùå Fichier CSV de test non trouv√©: {demo_file}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Erreur test CSV: {e}")
        return False

def show_system_summary():
    """Affiche un r√©sum√© complet du syst√®me"""
    logger.info("üìã === R√âSUM√â DU SYST√àME ===")
    
    # Donn√©es historiques
    odds_dir = 'data/odds/raw_data'
    if os.path.exists(odds_dir):
        odds_files = [f for f in os.listdir(odds_dir) if f.endswith('.csv')]
        
        total_lines = 0
        for file in odds_files[:5]:  # Compter les 5 premiers
            try:
                import pandas as pd
                df = pd.read_csv(os.path.join(odds_dir, file))
                total_lines += len(df)
            except:
                pass
        
        logger.info(f"üìä Donn√©es historiques:")
        logger.info(f"   ‚Ä¢ {len(odds_files)} ligues couvertes")
        logger.info(f"   ‚Ä¢ ~{total_lines:,} cotes historiques (√©chantillon)")
    
    # Pr√©dictions
    predictions_dir = 'data/predictions'
    if os.path.exists(predictions_dir):
        pred_files = [f for f in os.listdir(predictions_dir) if f.endswith('.csv')]
        logger.info(f"üéØ Pr√©dictions g√©n√©r√©es:")
        logger.info(f"   ‚Ä¢ {len(pred_files)} fichiers de pr√©dictions")
        
        # D√©tails du dernier fichier
        if pred_files:
            latest_file = max(pred_files)
            try:
                import pandas as pd
                df = pd.read_csv(os.path.join(predictions_dir, latest_file))
                similarity_cols = [col for col in df.columns if col.endswith('_similarity_pct')]
                logger.info(f"   ‚Ä¢ Dernier fichier: {latest_file}")
                logger.info(f"   ‚Ä¢ {len(df)} matchs analys√©s")
                logger.info(f"   ‚Ä¢ {len(similarity_cols)} types de paris")
            except:
                pass
    
    # Capacit√©s du syst√®me
    logger.info("üöÄ Capacit√©s du syst√®me:")
    logger.info("   ‚Ä¢ Analyse de similarit√© bas√©e sur 15 ligues")
    logger.info("   ‚Ä¢ Support de 1000+ types de paris diff√©rents")
    logger.info("   ‚Ä¢ G√©n√©ration de CSV quotidiens et historiques")
    logger.info("   ‚Ä¢ Syst√®me de scoring de confiance")
    logger.info("   ‚Ä¢ Analyses statistiques avanc√©es")
    logger.info("   ‚Ä¢ Scheduling automatique (pr√™t)")

def generate_sample_report():
    """G√©n√®re un rapport d'exemple avec les meilleures pr√©dictions"""
    logger.info("üìà === RAPPORT D'EXEMPLE ===")
    
    try:
        import pandas as pd
        
        demo_file = 'data/predictions/demo_daily_2025-08-22.csv'
        if os.path.exists(demo_file):
            df = pd.read_csv(demo_file)
            
            # Trouver les meilleures pr√©dictions
            similarity_cols = [col for col in df.columns if col.endswith('_similarity_pct')]
            confidence_cols = [col for col in df.columns if col.endswith('_confidence')]
            
            best_predictions = []
            
            for _, row in df.iterrows():
                match_name = f"{row['home_team']} vs {row['away_team']}"
                league = row['league_name']
                
                for col in confidence_cols:
                    if pd.notna(row[col]) and row[col] >= 80:
                        bet_type = col.replace('_confidence', '')
                        similarity_col = f"{bet_type}_similarity_pct"
                        odd_col = f"{bet_type}_target_odd"
                        
                        if similarity_col in df.columns and odd_col in df.columns:
                            best_predictions.append({
                                'match': match_name,
                                'league': league,
                                'bet_type': bet_type.replace('_', ' ')[:40],
                                'confidence': row[col],
                                'similarity': row.get(similarity_col, 'N/A'),
                                'odd': row.get(odd_col, 'N/A')
                            })
            
            # Trier par confiance
            best_predictions = sorted(best_predictions, key=lambda x: x['confidence'], reverse=True)
            
            logger.info("üî• TOP PR√âDICTIONS (Confiance ‚â• 80%):")
            for i, pred in enumerate(best_predictions[:10]):
                logger.info(f"{i+1:2d}. {pred['match'][:30]:30} | {pred['league'][:15]:15} | {pred['bet_type']:40} | Conf: {pred['confidence']:5.1f}% | Sim: {pred['similarity']:5.1f}% | Cote: {pred['odd']}")
            
            if not best_predictions:
                logger.info("   Aucune pr√©diction avec confiance ‚â• 80% dans cet √©chantillon")
                logger.info("   (R√©duisez le seuil ou attendez plus de donn√©es historiques)")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration rapport: {e}")

def main():
    """Test complet du syst√®me"""
    print("""
‚öΩ ================================================ ‚öΩ
   TEST COMPLET SYST√àME PR√âDICTIONS FOOTBALL       
‚öΩ ================================================ ‚öΩ
""")
    
    tests = [
        ("Int√©grit√© des donn√©es", test_data_integrity),
        ("Workflow d√©monstration", test_demo_workflow),
        ("Format CSV", test_csv_format),
        ("Analyseur", test_analyzer),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logger.info(f"\n--- {test_name} ---")
        if test_func():
            passed += 1
            logger.info(f"‚úÖ {test_name}: R√âUSSI")
        else:
            logger.error(f"‚ùå {test_name}: √âCHOU√â")
    
    # R√©sum√© des tests
    logger.info(f"\nüèÜ === R√âSULTATS DES TESTS ===")
    logger.info(f"‚úÖ Tests r√©ussis: {passed}/{total}")
    
    if passed == total:
        logger.info("üéâ TOUS LES TESTS SONT PASS√âS !")
        
        # Afficher le r√©sum√© du syst√®me
        show_system_summary()
        
        # G√©n√©rer un rapport d'exemple
        generate_sample_report()
        
        logger.info("\nüöÄ === SYST√àME PR√äT √Ä L'EMPLOI ===")
        logger.info("Le syst√®me de pr√©dictions est op√©rationnel !")
        logger.info("Prochaines √©tapes:")
        logger.info("1. Configurez RAPIDAPI_KEY pour utilisation en production")
        logger.info("2. Lancez le scheduler: python3 scheduler_predictions.py")
        logger.info("3. Ou utilisez: python3 quick_start.py --run")
        
    else:
        logger.error("‚ùå Certains tests ont √©chou√©")
        logger.info("üí° V√©rifiez les erreurs ci-dessus et corrigez-les")

if __name__ == "__main__":
    main()